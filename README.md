# ğŸ“Š Tratativa e AnÃ¡lise de Dados de CNPJ â€” Dezembro/2025
![Python](https://img.shields.io/badge/Python-3.x-blue?logo=python&logoColor=white)
![Apache Spark](https://img.shields.io/badge/Apache%20Spark-4.1-orange?logo=apachespark&logoColor=white)
![Delta Lake](https://img.shields.io/badge/Delta%20Lake-4.0-blueviolet)
![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange?logo=jupyter&logoColor=white)
![Linux](https://img.shields.io/badge/Linux-Ubuntu-E95420?logo=ubuntu&logoColor=white)
![Data Engineering](https://img.shields.io/badge/Data-Engineering-success)
![Public Data](https://img.shields.io/badge/Data-Public%20Dataset-informational)
![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)
![Status](https://img.shields.io/badge/Status-Em%20Desenvolvimento-yellow)

Projeto dedicado Ã  **coleta, organizaÃ§Ã£o, tratamento e anÃ¡lise** dos dados pÃºblicos de **CNPJ (Cadastro Nacional da Pessoa JurÃ­dica)** referentes a **dezembro de 2025**, disponibilizados pelo portal **dados.gov.br**.

O objetivo principal Ã© estruturar os dados brutos, realizar tratativas e possibilitar a geraÃ§Ã£o de **insights analÃ­ticos** sobre empresas brasileiras, como natureza jurÃ­dica, porte, localizaÃ§Ã£o, CNAE, regime do Simples Nacional, sÃ³cios, entre outros.

---

## ğŸ§  Objetivos do Projeto

- Coletar dados pÃºblicos de CNPJ no padrÃ£o oficial
- Organizar os arquivos em uma estrutura clara (RAW â†’ TRS)
- Realizar tratamento e padronizaÃ§Ã£o dos dados
- Preparar o dataset para anÃ¡lises exploratÃ³rias e futuras visualizaÃ§Ãµes
- Servir como base para estudos, dashboards e pipelines de dados

---

## ğŸ—‚ï¸ Estrutura do Projeto

```text
CNPJ_12-2025/
â”œâ”€â”€ .venv/                     # Ambiente virtual Python
â”œâ”€â”€ LND/                       # Camada de landing (dados organizados por domÃ­nio)
â”‚   â”œâ”€â”€ cnaes/
â”‚   â”œâ”€â”€ empresas/
â”‚   â”œâ”€â”€ estabelecimentos/
â”‚   â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ motivos/
â”‚   â”œâ”€â”€ municipios/
â”‚   â”œâ”€â”€ naturezas/
â”‚   â”œâ”€â”€ paises/
â”‚   â”œâ”€â”€ qualificacoes/
â”‚   â”œâ”€â”€ simples/
â”‚   â””â”€â”€ socios/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_NOTEBOOKS_RAW/      # Tratativa inicial dos dados brutos
â”‚   â”‚   â”œâ”€â”€ 01_socios.ipynb
â”‚   â”‚   â”œâ”€â”€ 02_simples.ipynb
â”‚   â”‚   â”œâ”€â”€ 03_paises.ipynb
â”‚   â”‚   â”œâ”€â”€ 04_qualificacoes.ipynb
â”‚   â”‚   â”œâ”€â”€ 05_naturezas.ipynb
â”‚   â”‚   â”œâ”€â”€ 06_municipios.ipynb
â”‚   â”‚   â”œâ”€â”€ 07_motivos.ipynb
â”‚   â”‚   â”œâ”€â”€ 08_estabelecimentos.ipynb
â”‚   â”‚   â”œâ”€â”€ 09_empresas.ipynb
â”‚   â”‚   â””â”€â”€ 10_cnaes.ipynb
â”‚   â”‚
â”‚   â”œâ”€â”€ 02_NOTEBOOKS_TRS/      # TransformaÃ§Ãµes e consolidaÃ§Ãµes
â”‚   â”‚   â”œâ”€â”€ 01_socios.ipynb
â”‚   â”‚   â”œâ”€â”€ 02_simples.ipynb
â”‚   â”‚   â”œâ”€â”€ 03_paises.ipynb
â”‚   â”‚   â”œâ”€â”€ 04_qualificacoes.ipynb
â”‚   â”‚   â”œâ”€â”€ 05_naturezas.ipynb
â”‚   â”‚   â”œâ”€â”€ 06_municipios.ipynb
â”‚   â”‚   â”œâ”€â”€ 07_motivos.ipynb
â”‚   â”‚   â”œâ”€â”€ 08_estabelecimentos.ipynb
â”‚   â”‚   â”œâ”€â”€ 09_empresas.ipynb
â”‚   â”‚   â””â”€â”€ 10_cnaes.ipynb
â”‚   â””â”€â”€ 01_coleta_dados.ipynb
â”‚
â”œâ”€â”€ RAW/                       # Dados brutos, sem tratamento
â”‚   â”œâ”€â”€ cnae/
â”‚   â”œâ”€â”€ empresas/
â”‚   â”œâ”€â”€ estabelecimentos/
â”‚   â”œâ”€â”€ motivos/
â”‚   â”œâ”€â”€ municipios/
â”‚   â”œâ”€â”€ naturezas/
â”‚   â”œâ”€â”€ paises/
â”‚   â”œâ”€â”€ qualificacoes/
â”‚   â”œâ”€â”€ simples/
â”‚   â””â”€â”€ socios/
â”‚
â”œâ”€â”€ TRS/                       # Dados tratados e prontos para anÃ¡lise
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

## ğŸ› ï¸ Tecnologias Utilizadas

- Python 3
- Jupyter Notebook / JupyterLab
- Apache Spark (PySpark)
- Delta Lake (delta-spark)
- Requests (coleta de dados via HTTP)
- WSL + Ubuntu (ambiente de desenvolvimento)
> O uso do Spark permite escalabilidade e processamento eficiente de grandes volumes de dados.

---

## ğŸ“¦ InstalaÃ§Ã£o do Ambiente

1ï¸âƒ£ Crie e ative um ambiente virtual (opcional, mas altamente recomendado)
```bash
python -m venv .venv
source .venv/bin/activate  # Linux / WSL
```
2ï¸âƒ£ Instale as dependÃªncias

```bash
pip install -r requirements.txt
```
## ğŸ“‘ Principais DependÃªncias
Algumas bibliotecas-chave utilizadas no projeto:
- ``pyspark==4.1.1``
- ``delta-spark==4.0.0``
- ``requests==2.32.5``
- ``jupyterlab==4.5.1``
- ``ipykernel==7.1.0``
> A lista completa estÃ¡ disponÃ­vel no arquivo ``requirements.txt``.

---
## ğŸ“„ LicenÃ§a

Este projeto utiliza dados pÃºblicos, sendo destinado a fins educacionais, analÃ­ticos e experimentais.

## âœï¸ Autor

Desenvolvido por Williams
Foco em Engenharia de Dados, Python e Banco de Dados
